otbuser@d247ec3948b3:/data$ 
python training_v5.py \
  --model_dir /data/output/savedmodel_v5 \
  --log_dir /data/logs/savedmodel_v5 \
  --epochs 50 \
  --ckpt_dir /data/ckpts/savedmodel_v5
2024-10-23 07:40:52.436007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/opt/otbtf/lib/python3/dist-packages/osgeo/gdal.py:315: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.
  warnings.warn(
Model: "FCNNModel"
______________________________________________________________________________________________________________________________________________________
 Layer (type)                                Output Shape                                 Param #        Connected to                                 
======================================================================================================================================================
 input_ge (InputLayer)                       [(None, None, None, 3)]                      0              []                                           
                                                                                                                                                      
 tf.cast (TFOpLambda)                        (None, None, None, 3)                        0              ['input_ge[0][0]']                           
                                                                                                                                                      
 tf.math.multiply (TFOpLambda)               (None, None, None, 3)                        0              ['tf.cast[0][0]']                            
                                                                                                                                                      
 conv1 (Conv2D)                              (None, None, None, 16)                       448            ['tf.math.multiply[0][0]']                   
                                                                                                                                                      
 conv2 (Conv2D)                              (None, None, None, 32)                       4640           ['conv1[0][0]']                              
                                                                                                                                                      
 conv3 (Conv2D)                              (None, None, None, 64)                       18496          ['conv2[0][0]']                              
                                                                                                                                                      
 conv4 (Conv2D)                              (None, None, None, 64)                       36928          ['conv3[0][0]']                              
                                                                                                                                                      
 conv1t (Conv2DTranspose)                    (None, None, None, 64)                       36928          ['conv4[0][0]']                              
                                                                                                                                                      
 tf.__operators__.add (TFOpLambda)           (None, None, None, 64)                       0              ['conv1t[0][0]',                             
                                                                                                          'conv3[0][0]']                              
                                                                                                                                                      
 conv2t (Conv2DTranspose)                    (None, None, None, 32)                       18464          ['tf.__operators__.add[0][0]']               
                                                                                                                                                      
 tf.__operators__.add_1 (TFOpLambda)         (None, None, None, 32)                       0              ['conv2t[0][0]',                             
                                                                                                          'conv2[0][0]']                              
                                                                                                                                                      
 conv3t (Conv2DTranspose)                    (None, None, None, 16)                       4624           ['tf.__operators__.add_1[0][0]']             
                                                                                                                                                      
 tf.__operators__.add_2 (TFOpLambda)         (None, None, None, 16)                       0              ['conv3t[0][0]',                             
                                                                                                          'conv1[0][0]']                              
                                                                                                                                                      
 softmax_layer (Conv2DTranspose)             (None, None, None, 3)                        435            ['tf.__operators__.add_2[0][0]']             
                                                                                                                                                      
 argmax_layer (Argmax)                       (None, None, None, 1)                        0              ['softmax_layer[0][0]']                      
                                                                                                                                                      
 tf.__operators__.getitem_4 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem (SlicingOpLambda)  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
                                                                                                                                                      
 tf.__operators__.getitem_1 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_2 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_3 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_9 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_5 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_6 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_7 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_8 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 softmax_layer_crop128 (Activation)          (None, None, None, 3)                        0              ['tf.__operators__.getitem_4[0][0]']         
                                                                                                                                                      
 softmax_layer_crop16 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem[0][0]']           
                                                                                                                                                      
 softmax_layer_crop32 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_1[0][0]']         
                                                                                                                                                      
 softmax_layer_crop64 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_2[0][0]']         
                                                                                                                                                      
 softmax_layer_crop96 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_3[0][0]']         
                                                                                                                                                      
 argmax_layer_crop128 (Activation)           (None, None, None, 1)                        0              ['tf.__operators__.getitem_9[0][0]']         
                                                                                                                                                      
 argmax_layer_crop16 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_5[0][0]']         
                                                                                                                                                      
 argmax_layer_crop32 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_6[0][0]']         
                                                                                                                                                      
 argmax_layer_crop64 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_7[0][0]']         
                                                                                                                                                      
 argmax_layer_crop96 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_8[0][0]']         
                                                                                                                                                      
======================================================================================================================================================
Total params: 120963 (472.51 KB)
Trainable params: 120963 (472.51 KB)
Non-trainable params: 0 (0.00 Byte)
______________________________________________________________________________________________________________________________________________________
2024-10-23 07:40:55.224664: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2024-10-23 07:40:55.229977: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:118] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency
Epoch 3/50
2571/2571 [==============================] - 12s 4ms/step - loss: 2318475198464.0000 - softmax_layer_loss: 2318475198464.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1134 - softmax_layer_recall_1: 0.4622 - softmax_layer_precision_2: 0.2001 - softmax_layer_recall_2: 0.4429 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1821 - softmax_layer_fscore_cls2: 0.2756 - val_loss: 5195256299520.0000 - val_softmax_layer_loss: 5195256299520.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1058 - val_softmax_layer_recall_1: 0.4179 - val_softmax_layer_precision_2: 0.2078 - val_softmax_layer_recall_2: 0.3916 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1689 - val_softmax_layer_fscore_cls2: 0.2715
Epoch 4/50
2571/2571 [==============================] - 9s 3ms/step - loss: 11450377568256.0000 - softmax_layer_loss: 11450377568256.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1140 - softmax_layer_recall_1: 0.4536 - softmax_layer_precision_2: 0.1991 - softmax_layer_recall_2: 0.4448 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1822 - softmax_layer_fscore_cls2: 0.2751 - val_loss: 19060041449472.0000 - val_softmax_layer_loss: 19060041449472.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.3185 - val_softmax_layer_precision_2: 0.2080 - val_softmax_layer_recall_2: 0.5945 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1594 - val_softmax_layer_fscore_cls2: 0.3082
Epoch 5/50
2571/2571 [==============================] - 9s 3ms/step - loss: 33138554175488.0000 - softmax_layer_loss: 33138554175488.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1113 - softmax_layer_recall_1: 0.4442 - softmax_layer_precision_2: 0.2000 - softmax_layer_recall_2: 0.4452 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1780 - softmax_layer_fscore_cls2: 0.2760 - val_loss: 45151959384064.0000 - val_softmax_layer_loss: 45151959384064.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1054 - val_softmax_layer_recall_1: 0.4443 - val_softmax_layer_precision_2: 0.2078 - val_softmax_layer_recall_2: 0.3678 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1704 - val_softmax_layer_fscore_cls2: 0.2655
2024-10-23 07:41:25.456709: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
Epoch 6/50
2571/2571 [==============================] - 9s 3ms/step - loss: 71881629630464.0000 - softmax_layer_loss: 71881629630464.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1129 - softmax_layer_recall_1: 0.4546 - softmax_layer_precision_2: 0.1998 - softmax_layer_recall_2: 0.4392 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1809 - softmax_layer_fscore_cls2: 0.2746 - val_loss: 84384329760768.0000 - val_softmax_layer_loss: 84384329760768.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1047 - val_softmax_layer_recall_1: 0.5668 - val_softmax_layer_precision_2: 0.2078 - val_softmax_layer_recall_2: 0.4246 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1768 - val_softmax_layer_fscore_cls2: 0.2790
Epoch 7/50
2571/2571 [==============================] - 9s 3ms/step - loss: 143028752744448.0000 - softmax_layer_loss: 143028752744448.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4608 - softmax_layer_precision_2: 0.2007 - softmax_layer_recall_2: 0.4418 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1821 - softmax_layer_fscore_cls2: 0.2760 - val_loss: 191671975280640.0000 - val_softmax_layer_loss: 191671975280640.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1050 - val_softmax_layer_recall_1: 0.6741 - val_softmax_layer_precision_2: 0.2076 - val_softmax_layer_recall_2: 0.2677 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1817 - val_softmax_layer_fscore_cls2: 0.2338
Epoch 8/50
2571/2571 [==============================] - 9s 3ms/step - loss: 268363649515520.0000 - softmax_layer_loss: 268363649515520.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1141 - softmax_layer_recall_1: 0.4646 - softmax_layer_precision_2: 0.2005 - softmax_layer_recall_2: 0.4442 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1832 - softmax_layer_fscore_cls2: 0.2763 - val_loss: 290205537927168.0000 - val_softmax_layer_loss: 290205537927168.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1044 - val_softmax_layer_recall_1: 0.3997 - val_softmax_layer_precision_2: 0.2091 - val_softmax_layer_recall_2: 0.4727 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1656 - val_softmax_layer_fscore_cls2: 0.2899
Epoch 9/50
 853/2571 [========>.....................] - ETA: 16s - loss: 451402404986880.0000 - softmax_layer_loss: 451402404986880.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4604 - softmax_layer_precision_2: 0.1968 - softmax_layer_recall_2: 0.4370 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1822 - softmax_layer_fscore_cls2: 0.27142024-10-23 07:42:00.797760: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: 452661904146432.0000 - softmax_layer_loss: 452661904146432.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4600 - softmax_layer_precision_2: 0.1967 - softmax_layer_recall_2: 0.4364 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1821 - softmax_layer_fscore_cls2: 0.2712 - val_loss: 519412272594944.0000 - val_softmax_layer_loss: 519412272594944.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1062 - val_softmax_layer_recall_1: 0.2047 - val_softmax_layer_precision_2: 0.2074 - val_softmax_layer_recall_2: 0.6786 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1398 - val_softmax_layer_fscore_cls2: 0.3177
Epoch 10/50
2571/2571 [==============================] - 9s 3ms/step - loss: 762981277237248.0000 - softmax_layer_loss: 762981277237248.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1147 - softmax_layer_recall_1: 0.4648 - softmax_layer_precision_2: 0.2017 - softmax_layer_recall_2: 0.4498 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1840 - softmax_layer_fscore_cls2: 0.2785 - val_loss: 1208795728445440.0000 - val_softmax_layer_loss: 1208795728445440.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1047 - val_softmax_layer_recall_1: 0.2764 - val_softmax_layer_precision_2: 0.2068 - val_softmax_layer_recall_2: 0.7149 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1518 - val_softmax_layer_fscore_cls2: 0.3208
Epoch 11/50
2571/2571 [==============================] - 9s 3ms/step - loss: 1193764953522176.0000 - softmax_layer_loss: 1193764953522176.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4583 - softmax_layer_precision_2: 0.1977 - softmax_layer_recall_2: 0.4436 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1820 - softmax_layer_fscore_cls2: 0.2735 - val_loss: 1578586507051008.0000 - val_softmax_layer_loss: 1578586507051008.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.4770 - val_softmax_layer_precision_2: 0.2071 - val_softmax_layer_recall_2: 0.3715 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1738 - val_softmax_layer_fscore_cls2: 0.2660
Epoch 12/50
2571/2571 [==============================] - 9s 3ms/step - loss: 1880704438763520.0000 - softmax_layer_loss: 1880704438763520.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1113 - softmax_layer_recall_1: 0.4524 - softmax_layer_precision_2: 0.2001 - softmax_layer_recall_2: 0.4472 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1787 - softmax_layer_fscore_cls2: 0.2765 - val_loss: 2120684931121152.0000 - val_softmax_layer_loss: 2120684931121152.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.5030 - val_softmax_layer_precision_2: 0.2060 - val_softmax_layer_recall_2: 0.4898 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1755 - val_softmax_layer_fscore_cls2: 0.2900
Epoch 13/50
 853/2571 [========>.....................] - ETA: 16s - loss: 2738217476423680.0000 - softmax_layer_loss: 2738217476423680.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1121 - softmax_layer_recall_1: 0.4533 - softmax_layer_precision_2: 0.2014 - softmax_layer_recall_2: 0.4509 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1797 - softmax_layer_fscore_cls2: 0.27852024-10-23 07:42:36.861945: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: 2741498294566912.0000 - softmax_layer_loss: 2741498294566912.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1121 - softmax_layer_recall_1: 0.4535 - softmax_layer_precision_2: 0.2015 - softmax_layer_recall_2: 0.4508 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1798 - softmax_layer_fscore_cls2: 0.2785 - val_loss: 2985131925045248.0000 - val_softmax_layer_loss: 2985131925045248.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.3646 - val_softmax_layer_precision_2: 0.2085 - val_softmax_layer_recall_2: 0.6235 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1646 - val_softmax_layer_fscore_cls2: 0.3125
Epoch 14/50
2571/2571 [==============================] - 9s 3ms/step - loss: 4086508910804992.0000 - softmax_layer_loss: 4086508910804992.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1133 - softmax_layer_recall_1: 0.4580 - softmax_layer_precision_2: 0.2033 - softmax_layer_recall_2: 0.4561 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1816 - softmax_layer_fscore_cls2: 0.2812 - val_loss: 4118127386296320.0000 - val_softmax_layer_loss: 4118127386296320.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.6397 - val_softmax_layer_precision_2: 0.2094 - val_softmax_layer_recall_2: 0.3528 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1824 - val_softmax_layer_fscore_cls2: 0.2628
Epoch 15/50
2571/2571 [==============================] - 9s 3ms/step - loss: 5586958420017152.0000 - softmax_layer_loss: 5586958420017152.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1118 - softmax_layer_recall_1: 0.4551 - softmax_layer_precision_2: 0.2028 - softmax_layer_recall_2: 0.4513 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1794 - softmax_layer_fscore_cls2: 0.2798 - val_loss: 5809904266772480.0000 - val_softmax_layer_loss: 5809904266772480.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1063 - val_softmax_layer_recall_1: 0.5529 - val_softmax_layer_precision_2: 0.2071 - val_softmax_layer_recall_2: 0.2217 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1783 - val_softmax_layer_fscore_cls2: 0.2141
Epoch 16/50
2571/2571 [==============================] - 9s 3ms/step - loss: 7751113520447488.0000 - softmax_layer_loss: 7751113520447488.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1139 - softmax_layer_recall_1: 0.4620 - softmax_layer_precision_2: 0.2018 - softmax_layer_recall_2: 0.4498 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1827 - softmax_layer_fscore_cls2: 0.2786 - val_loss: 7279277003243520.0000 - val_softmax_layer_loss: 7279277003243520.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1064 - val_softmax_layer_recall_1: 0.5649 - val_softmax_layer_precision_2: 0.2069 - val_softmax_layer_recall_2: 0.2829 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1790 - val_softmax_layer_fscore_cls2: 0.2390
Epoch 17/50
 852/2571 [========>.....................] - ETA: 16s - loss: 10184800904151040.0000 - softmax_layer_loss: 10184800904151040.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4592 - softmax_layer_precision_2: 0.2012 - softmax_layer_recall_2: 0.4476 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1820 - softmax_layer_fscore_cls2: 0.27762024-10-23 07:43:12.867169: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: 10167916313968640.0000 - softmax_layer_loss: 10167916313968640.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1132 - softmax_layer_recall_1: 0.4588 - softmax_layer_precision_2: 0.2011 - softmax_layer_recall_2: 0.4481 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1816 - softmax_layer_fscore_cls2: 0.2776 - val_loss: 11368939493785600.0000 - val_softmax_layer_loss: 11368939493785600.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1053 - val_softmax_layer_recall_1: 0.2393 - val_softmax_layer_precision_2: 0.2094 - val_softmax_layer_recall_2: 0.5160 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1463 - val_softmax_layer_fscore_cls2: 0.2979
Epoch 18/50
2571/2571 [==============================] - 9s 3ms/step - loss: 14123648839319552.0000 - softmax_layer_loss: 14123648839319552.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1133 - softmax_layer_recall_1: 0.4585 - softmax_layer_precision_2: 0.2004 - softmax_layer_recall_2: 0.4472 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1818 - softmax_layer_fscore_cls2: 0.2768 - val_loss: 15693203835453440.0000 - val_softmax_layer_loss: 15693203835453440.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1038 - val_softmax_layer_recall_1: 0.3628 - val_softmax_layer_precision_2: 0.2086 - val_softmax_layer_recall_2: 0.6220 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1614 - val_softmax_layer_fscore_cls2: 0.3124
Epoch 19/50
2571/2571 [==============================] - 9s 3ms/step - loss: 17959349913649152.0000 - softmax_layer_loss: 17959349913649152.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1140 - softmax_layer_recall_1: 0.4599 - softmax_layer_precision_2: 0.1996 - softmax_layer_recall_2: 0.4480 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1827 - softmax_layer_fscore_cls2: 0.2762 - val_loss: 19064028387082240.0000 - val_softmax_layer_loss: 19064028387082240.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1047 - val_softmax_layer_recall_1: 0.4820 - val_softmax_layer_precision_2: 0.2074 - val_softmax_layer_recall_2: 0.4599 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1721 - val_softmax_layer_fscore_cls2: 0.2859
Epoch 20/50
2571/2571 [==============================] - 9s 3ms/step - loss: 23070053905727488.0000 - softmax_layer_loss: 23070053905727488.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1135 - softmax_layer_recall_1: 0.4574 - softmax_layer_precision_2: 0.2000 - softmax_layer_recall_2: 0.4479 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1819 - softmax_layer_fscore_cls2: 0.2765 - val_loss: 27653290816700416.0000 - val_softmax_layer_loss: 27653290816700416.0000 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1053 - val_softmax_layer_recall_1: 0.3323 - val_softmax_layer_precision_2: 0.2084 - val_softmax_layer_recall_2: 0.4195 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1600 - val_softmax_layer_fscore_cls2: 0.2785
Epoch 21/50
 852/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1181 - softmax_layer_recall_1: 0.1056 - softmax_layer_precision_2: 0.1982 - softmax_layer_recall_2: 0.0985 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1115 - softmax_layer_fscore_cls2: 0.13162024-10-23 07:43:49.014876: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1181 - softmax_layer_recall_1: 0.1046 - softmax_layer_precision_2: 0.1982 - softmax_layer_recall_2: 0.0982 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1110 - softmax_layer_fscore_cls2: 0.1313 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 22/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 23/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 24/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 25/50
 857/2571 [=========>....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:44:24.939388: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 26/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 27/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 28/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 29/50
 855/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:45:00.846383: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 30/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 31/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 32/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 33/50
 852/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:45:36.857071: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 34/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 35/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 36/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 37/50
 853/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:46:12.921018: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 38/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 39/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 40/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 41/50
 852/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:46:49.051715: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 42/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 43/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 44/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 45/50
 857/2571 [=========>....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:47:25.317520: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 46/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 47/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 48/50
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 49/50
 852/2571 [========>.....................] - ETA: 16s - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+002024-10-23 07:48:01.701627: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2571/2571 [==============================] - 9s 3ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
Epoch 50/50
2571/2571 [==============================] - 9s 4ms/step - loss: nan - softmax_layer_loss: nan - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.0000e+00 - softmax_layer_recall_1: 0.0000e+00 - softmax_layer_precision_2: 0.0000e+00 - softmax_layer_recall_2: 0.0000e+00 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.0000e+00 - softmax_layer_fscore_cls2: 0.0000e+00 - val_loss: nan - val_softmax_layer_loss: nan - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.0000e+00 - val_softmax_layer_recall_1: 0.0000e+00 - val_softmax_layer_precision_2: 0.0000e+00 - val_softmax_layer_recall_2: 0.0000e+00 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0000e+00 - val_softmax_layer_fscore_cls2: 0.0000e+00
2024-10-23 07:48:11.578816: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /data/output/savedmodel_v5: FAILED_PRECONDITION: /data/output/savedmodel_v5; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
109/109 [==============================] - 1s 5ms/step - loss: 5271630905344.0000 - softmax_layer_loss: 5271630905344.0000 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.1028 - softmax_layer_recall_1: 0.4179 - softmax_layer_precision_2: 0.2198 - softmax_layer_recall_2: 0.3918 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1650 - softmax_layer_fscore_cls2: 0.2816
loss: 527163090534400.00
softmax_layer_loss: 527163090534400.00
softmax_layer_precision: 0.00
softmax_layer_recall: 0.00
softmax_layer_precision_1: 10.28
softmax_layer_recall_1: 41.79
softmax_layer_precision_2: 21.98
softmax_layer_recall_2: 39.18
softmax_layer_fscore_cls0: 0.00
softmax_layer_fscore_cls1: 16.50
softmax_layer_fscore_cls2: 28.16
otbuser@d247ec3948b3:/data$ python inference_v5.py \
  --model_dir /data/output/savedmodel_v5
2024-10-23 07:49:37 (INFO) [pyotb] Successfully loaded 117 OTB applications
2024-10-23 07:49:37 (INFO) [pyotb] TensorflowModelServe: argument for parameter "source1.il" was converted to list
2024-10-23 07:49:37 (INFO) [pyotb] TensorflowModelServe: argument for parameter "output.names" was converted to list
2024-10-23 07:49:37.169801: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /data/output/savedmodel_v5
2024-10-23 07:49:37.180606: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }
2024-10-23 07:49:37.180799: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /data/output/savedmodel_v5
2024-10-23 07:49:37.182942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-23 07:49:37.232878: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled
2024-10-23 07:49:37.248683: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.
2024-10-23 07:49:37.257795: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:118] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency
2024-10-23 07:49:37.473461: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2024-10-23 07:49:37.473501: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2024-10-23 07:49:37.502826: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.
2024-10-23 07:49:37.503650: W tensorflow/core/profiler/convert/xplane_to_step_stats.cc:78] GPU trace was not collected.
2024-10-23 07:49:37.504251: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2024-10-23 07:49:37.505022: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /data/output/savedmodel_v5
2024-10-23 07:49:37.534321: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2024-10-23 07:49:37.534349: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2024-10-23 07:49:37.534429: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.
2024-10-23 07:49:37.534455: W tensorflow/core/profiler/convert/xplane_to_step_stats.cc:78] GPU trace was not collected.
2024-10-23 07:49:37.534469: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2024-10-23 07:49:37.534721: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 365268 microseconds.
2024-10-23 07:49:37 (INFO): Loading metadata from official product
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Source info :
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Receptive field  : [128, 128]
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Placeholder name : input_ge
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Output spacing ratio: 1
2024-10-23 07:49:37 (INFO) TensorflowModelServe: The TensorFlow model is used in fully convolutional mode
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Setting background value to 0
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Output field of expression: [64, 64]
2024-10-23 07:49:37 (WARNING) TensorflowModelServe: Aligning the tiling to the output expression field for better performances (dim 0). New value set to 64
2024-10-23 07:49:37 (WARNING) TensorflowModelServe: Aligning the tiling to the output expression field for better performances (dim 1). New value set to 64
2024-10-23 07:49:37 (INFO) TensorflowModelServe: Force tiling with squared tiles of [64, 64]
2024-10-23 07:49:37 (INFO): Default RAM limit for OTB is 256 MB
2024-10-23 07:49:37 (INFO): GDAL maximum cache size is 392 MB
2024-10-23 07:49:37 (INFO): OTB will use at most 8 threads
2024-10-23 07:49:37 (INFO): Estimated memory for full processing: 10410.8MB (avail.: 256 MB), optimal image partitioning: 41 blocks
2024-10-23 07:49:37 (INFO): File /data/map_v5.tif will be written in 49 blocks of 992x992 pixels
Writing /data/map_v5.tif...: 0% [                                               Writing /data/map_v5.tif...: 2% [*                                              Writing /data/map_v5.tif...: 4% [**                                             Writing /data/map_v5.tif...: 6% [***                                            Writing /data/map_v5.tif...: 8% [****                                           Writing /data/map_v5.tif...: 10% [*****                                         Writing /data/map_v5.tif...: 12% [******                                        Writing /data/map_v5.tif...: 14% [*******                                       Writing /data/map_v5.tif...: 16% [********                                      Writing /data/map_v5.tif...: 18% [*********                                     Writing /data/map_v5.tif...: 20% [**********                                    Writing /data/map_v5.tif...: 22% [***********                                   Writing /data/map_v5.tif...: 24% [************                                  Writing /data/map_v5.tif...: 26% [*************                                 Writing /data/map_v5.tif...: 28% [**************                                Writing /data/map_v5.tif...: 30% [***************                               Writing /data/map_v5.tif...: 32% [****************                              Writing /data/map_v5.tif...: 34% [*****************                             Writing /data/map_v5.tif...: 36% [******************                            Writing /data/map_v5.tif...: 38% [*******************                           Writing /data/map_v5.tif...: 40% [********************                          Writing /data/map_v5.tif...: 42% [*********************                         Writing /data/map_v5.tif...: 44% [**********************                        Writing /data/map_v5.tif...: 46% [***********************                       Writing /data/map_v5.tif...: 48% [************************                      Writing /data/map_v5.tif...: 50% [*************************                     Writing /data/map_v5.tif...: 52% [**************************                    Writing /data/map_v5.tif...: 54% [***************************                   Writing /data/map_v5.tif...: 56% [****************************                  Writing /data/map_v5.tif...: 58% [*****************************                 Writing /data/map_v5.tif...: 60% [******************************                Writing /data/map_v5.tif...: 62% [*******************************               Writing /data/map_v5.tif...: 64% [********************************              Writing /data/map_v5.tif...: 66% [*********************************             Writing /data/map_v5.tif...: 68% [**********************************            Writing /data/map_v5.tif...: 70% [***********************************           Writing /data/map_v5.tif...: 72% [************************************          Writing /data/map_v5.tif...: 74% [*************************************         Writing /data/map_v5.tif...: 76% [**************************************        Writing /data/map_v5.tif...: 78% [***************************************       Writing /data/map_v5.tif...: 80% [****************************************      Writing /data/map_v5.tif...: 82% [*****************************************     Writing /data/map_v5.tif...: 84% [******************************************    Writing /data/map_v5.tif...: 86% [*******************************************   Writing /data/map_v5.tif...: 88% [********************************************  Writing /data/map_v5.tif...: 90% [********************************************* Writing /data/map_v5.tif...: 92% [**********************************************Writing /data/map_v5.tif...: 94% [**********************************************Writing /data/map_v5.tif...: 96% [**********************************************Writing /data/map_v5.tif...: 98% [**********************************************Writing /data/map_v5.tif...: 100% [**************************************************] (49s)