otbuser@ebef67e1b7c4:/data$ python training_v11.py   --model_dir /data/output/savedmodel_v11   --log_dir /data/logs/savedmodel_v11   --epochs 50   --ckpt_dir /data/ckpts/savedmodel_v11
2024-10-23 13:37:57.741367: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/opt/otbtf/lib/python3/dist-packages/osgeo/gdal.py:315: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.
  warnings.warn(
Model: "FCNNModel"
______________________________________________________________________________________________________________________________________________________
 Layer (type)                                Output Shape                                 Param #        Connected to                                 
======================================================================================================================================================
 input_ge (InputLayer)                       [(None, None, None, 3)]                      0              []                                           
                                                                                                                                                      
 tf.cast (TFOpLambda)                        (None, None, None, 3)                        0              ['input_ge[0][0]']                           
                                                                                                                                                      
 tf.math.multiply (TFOpLambda)               (None, None, None, 3)                        0              ['tf.cast[0][0]']                            
                                                                                                                                                      
 conv1 (Conv2D)                              (None, None, None, 32)                       896            ['tf.math.multiply[0][0]']                   
                                                                                                                                                      
 batch_normalization (BatchNormalization)    (None, None, None, 32)                       128            ['conv1[0][0]']                              
                                                                                                                                                      
 conv2 (Conv2D)                              (None, None, None, 64)                       18496          ['batch_normalization[0][0]']                
                                                                                                                                                      
 batch_normalization_1 (BatchNormalization)  (None, None, None, 64)                       256            ['conv2[0][0]']                              
                                                                                                                                                      
 conv1t (Conv2DTranspose)                    (None, None, None, 32)                       18464          ['batch_normalization_1[0][0]']              
                                                                                                                                                      
 tf.__operators__.add (TFOpLambda)           (None, None, None, 32)                       0              ['conv1t[0][0]',                             
                                                                                                          'batch_normalization[0][0]']                
                                                                                                                                                      
 batch_normalization_2 (BatchNormalization)  (None, None, None, 32)                       128            ['tf.__operators__.add[0][0]']               
                                                                                                                                                      
 softmax_layer (Conv2DTranspose)             (None, None, None, 3)                        867            ['batch_normalization_2[0][0]']              
                                                                                                                                                      
 argmax_layer (Argmax)                       (None, None, None, 1)                        0              ['softmax_layer[0][0]']                      
                                                                                                                                                      
 tf.__operators__.getitem_4 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem (SlicingOpLambda)  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
                                                                                                                                                      
 tf.__operators__.getitem_1 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_2 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_3 (SlicingOpLambd  (None, None, None, 3)                        0              ['softmax_layer[0][0]']                      
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_9 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_5 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_6 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_7 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 tf.__operators__.getitem_8 (SlicingOpLambd  (None, None, None, 1)                        0              ['argmax_layer[0][0]']                       
 a)                                                                                                                                                   
                                                                                                                                                      
 softmax_layer_crop128 (Activation)          (None, None, None, 3)                        0              ['tf.__operators__.getitem_4[0][0]']         
                                                                                                                                                      
 softmax_layer_crop16 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem[0][0]']           
                                                                                                                                                      
 softmax_layer_crop32 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_1[0][0]']         
                                                                                                                                                      
 softmax_layer_crop64 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_2[0][0]']         
                                                                                                                                                      
 softmax_layer_crop96 (Activation)           (None, None, None, 3)                        0              ['tf.__operators__.getitem_3[0][0]']         
                                                                                                                                                      
 argmax_layer_crop128 (Activation)           (None, None, None, 1)                        0              ['tf.__operators__.getitem_9[0][0]']         
                                                                                                                                                      
 argmax_layer_crop16 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_5[0][0]']         
                                                                                                                                                      
 argmax_layer_crop32 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_6[0][0]']         
                                                                                                                                                      
 argmax_layer_crop64 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_7[0][0]']         
                                                                                                                                                      
 argmax_layer_crop96 (Activation)            (None, None, None, 1)                        0              ['tf.__operators__.getitem_8[0][0]']         
                                                                                                                                                      
======================================================================================================================================================
Total params: 39235 (153.26 KB)
Trainable params: 38979 (152.26 KB)
Non-trainable params: 256 (1.00 KB)
______________________________________________________________________________________________________________________________________________________
2024-10-23 13:37:59.804833: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2024-10-23 13:37:59.810672: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:118] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency
Epoch 1/50
60/60 [==============================] - 8s 109ms/step - loss: 0.1877 - softmax_layer_loss: 0.1877 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5605 - softmax_layer_recall_1: 0.8532 - softmax_layer_precision_2: 0.6413 - softmax_layer_recall_2: 0.7318 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6765 - softmax_layer_fscore_cls2: 0.6836 - val_loss: 0.2433 - val_softmax_layer_loss: 0.2433 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.8063 - val_softmax_layer_recall_1: 0.1525 - val_softmax_layer_precision_2: 0.1143 - val_softmax_layer_recall_2: 1.4654e-04 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2565 - val_softmax_layer_fscore_cls2: 2.9269e-04
Epoch 2/50
60/60 [==============================] - 6s 98ms/step - loss: 0.1624 - softmax_layer_loss: 0.1624 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7284 - softmax_layer_recall_1: 0.9231 - softmax_layer_precision_2: 0.7199 - softmax_layer_recall_2: 0.7983 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8143 - softmax_layer_fscore_cls2: 0.7571 - val_loss: 0.2265 - val_softmax_layer_loss: 0.2265 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.9353 - val_softmax_layer_recall_1: 0.5824 - val_softmax_layer_precision_2: 0.8196 - val_softmax_layer_recall_2: 0.3347 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.7178 - val_softmax_layer_fscore_cls2: 0.4753
Epoch 3/50
60/60 [==============================] - 6s 96ms/step - loss: 0.1797 - softmax_layer_loss: 0.1797 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7492 - softmax_layer_recall_1: 0.9186 - softmax_layer_precision_2: 0.7262 - softmax_layer_recall_2: 0.7513 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8253 - softmax_layer_fscore_cls2: 0.7385 - val_loss: 0.2069 - val_softmax_layer_loss: 0.2069 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.9217 - val_softmax_layer_recall_1: 0.0955 - val_softmax_layer_precision_2: 0.4162 - val_softmax_layer_recall_2: 0.1343 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1731 - val_softmax_layer_fscore_cls2: 0.2030
Epoch 4/50
60/60 [==============================] - 6s 99ms/step - loss: 0.1984 - softmax_layer_loss: 0.1984 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7574 - softmax_layer_recall_1: 0.8661 - softmax_layer_precision_2: 0.7302 - softmax_layer_recall_2: 0.7107 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8081 - softmax_layer_fscore_cls2: 0.7203 - val_loss: 0.1967 - val_softmax_layer_loss: 0.1967 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7883 - val_softmax_layer_recall_1: 0.3187 - val_softmax_layer_precision_2: 0.6887 - val_softmax_layer_recall_2: 0.4771 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.4539 - val_softmax_layer_fscore_cls2: 0.5637
Epoch 5/50
60/60 [==============================] - ETA: 0s - loss: 0.1899 - softmax_layer_loss: 0.1899 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.8029 - softmax_layer_recall_1: 0.8879 - softmax_layer_precision_2: 0.7845 - softmax_layer_recall_2: 0.7309 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8433 - softmax_layer_fscore_cls2: 0.75672024-10-23 13:38:30.529103: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 5s 81ms/step - loss: 0.1899 - softmax_layer_loss: 0.1899 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.8029 - softmax_layer_recall_1: 0.8879 - softmax_layer_precision_2: 0.7845 - softmax_layer_recall_2: 0.7309 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8433 - softmax_layer_fscore_cls2: 0.7567 - val_loss: 0.2070 - val_softmax_layer_loss: 0.2070 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.6308 - val_softmax_layer_recall_1: 0.1514 - val_softmax_layer_precision_2: 0.8217 - val_softmax_layer_recall_2: 0.7160 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2441 - val_softmax_layer_fscore_cls2: 0.7652
Epoch 6/50
60/60 [==============================] - 6s 99ms/step - loss: 0.2131 - softmax_layer_loss: 0.2131 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7618 - softmax_layer_recall_1: 0.7904 - softmax_layer_precision_2: 0.7615 - softmax_layer_recall_2: 0.6594 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.7759 - softmax_layer_fscore_cls2: 0.7067 - val_loss: 0.1823 - val_softmax_layer_loss: 0.1823 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7709 - val_softmax_layer_recall_1: 0.9697 - val_softmax_layer_precision_2: 0.8147 - val_softmax_layer_recall_2: 0.6724 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8590 - val_softmax_layer_fscore_cls2: 0.7367
Epoch 7/50
60/60 [==============================] - 5s 82ms/step - loss: 0.2174 - softmax_layer_loss: 0.2174 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7700 - softmax_layer_recall_1: 0.8024 - softmax_layer_precision_2: 0.7475 - softmax_layer_recall_2: 0.6038 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.7858 - softmax_layer_fscore_cls2: 0.6680 - val_loss: 0.2240 - val_softmax_layer_loss: 0.2240 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.8806 - val_softmax_layer_recall_1: 0.9114 - val_softmax_layer_precision_2: 0.6757 - val_softmax_layer_recall_2: 0.1465 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8958 - val_softmax_layer_fscore_cls2: 0.2408
Epoch 8/50
60/60 [==============================] - 5s 84ms/step - loss: 0.2290 - softmax_layer_loss: 0.2290 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7749 - softmax_layer_recall_1: 0.7508 - softmax_layer_precision_2: 0.7316 - softmax_layer_recall_2: 0.5503 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.7627 - softmax_layer_fscore_cls2: 0.6282 - val_loss: 0.2035 - val_softmax_layer_loss: 0.2035 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7868 - val_softmax_layer_recall_1: 0.9434 - val_softmax_layer_precision_2: 0.3178 - val_softmax_layer_recall_2: 0.0692 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8580 - val_softmax_layer_fscore_cls2: 0.1136
Epoch 9/50
60/60 [==============================] - 6s 107ms/step - loss: 0.2234 - softmax_layer_loss: 0.2234 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7639 - softmax_layer_recall_1: 0.7761 - softmax_layer_precision_2: 0.7732 - softmax_layer_recall_2: 0.6002 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.7700 - softmax_layer_fscore_cls2: 0.6758 - val_loss: 0.1575 - val_softmax_layer_loss: 0.1575 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.8449 - val_softmax_layer_recall_1: 0.9324 - val_softmax_layer_precision_2: 0.5900 - val_softmax_layer_recall_2: 0.2640 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8865 - val_softmax_layer_fscore_cls2: 0.3648
Epoch 10/50
60/60 [==============================] - 5s 86ms/step - loss: 0.2419 - softmax_layer_loss: 0.2419 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7443 - softmax_layer_recall_1: 0.7043 - softmax_layer_precision_2: 0.7608 - softmax_layer_recall_2: 0.5183 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.7237 - softmax_layer_fscore_cls2: 0.6165 - val_loss: 0.2053 - val_softmax_layer_loss: 0.2053 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7779 - val_softmax_layer_recall_1: 0.7393 - val_softmax_layer_precision_2: 0.8572 - val_softmax_layer_recall_2: 0.6999 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.7581 - val_softmax_layer_fscore_cls2: 0.7706
Epoch 11/50
60/60 [==============================] - ETA: 0s - loss: 0.2455 - softmax_layer_loss: 0.2455 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7067 - softmax_layer_recall_1: 0.5821 - softmax_layer_precision_2: 0.7261 - softmax_layer_recall_2: 0.5119 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6383 - softmax_layer_fscore_cls2: 0.60052024-10-23 13:39:03.956030: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 5s 86ms/step - loss: 0.2455 - softmax_layer_loss: 0.2455 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7067 - softmax_layer_recall_1: 0.5821 - softmax_layer_precision_2: 0.7261 - softmax_layer_recall_2: 0.5119 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6383 - softmax_layer_fscore_cls2: 0.6005 - val_loss: 0.1860 - val_softmax_layer_loss: 0.1860 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7393 - val_softmax_layer_recall_1: 0.9260 - val_softmax_layer_precision_2: 0.4920 - val_softmax_layer_recall_2: 0.1229 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8222 - val_softmax_layer_fscore_cls2: 0.1966
Epoch 12/50
60/60 [==============================] - 5s 86ms/step - loss: 0.2522 - softmax_layer_loss: 0.2522 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7138 - softmax_layer_recall_1: 0.5749 - softmax_layer_precision_2: 0.7336 - softmax_layer_recall_2: 0.4311 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6369 - softmax_layer_fscore_cls2: 0.5431 - val_loss: 0.1709 - val_softmax_layer_loss: 0.1709 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7596 - val_softmax_layer_recall_1: 0.9062 - val_softmax_layer_precision_2: 0.6537 - val_softmax_layer_recall_2: 0.3147 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8264 - val_softmax_layer_fscore_cls2: 0.4249
Epoch 13/50
60/60 [==============================] - 5s 86ms/step - loss: 0.2566 - softmax_layer_loss: 0.2566 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7061 - softmax_layer_recall_1: 0.5504 - softmax_layer_precision_2: 0.7384 - softmax_layer_recall_2: 0.4502 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6186 - softmax_layer_fscore_cls2: 0.5594 - val_loss: 0.1823 - val_softmax_layer_loss: 0.1823 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7822 - val_softmax_layer_recall_1: 0.9418 - val_softmax_layer_precision_2: 0.6635 - val_softmax_layer_recall_2: 0.2308 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8546 - val_softmax_layer_fscore_cls2: 0.3424
Epoch 14/50
60/60 [==============================] - 5s 85ms/step - loss: 0.2680 - softmax_layer_loss: 0.2680 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.6410 - softmax_layer_recall_1: 0.4407 - softmax_layer_precision_2: 0.6968 - softmax_layer_recall_2: 0.3795 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.5223 - softmax_layer_fscore_cls2: 0.4914 - val_loss: 0.1946 - val_softmax_layer_loss: 0.1946 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7137 - val_softmax_layer_recall_1: 0.9686 - val_softmax_layer_precision_2: 0.6213 - val_softmax_layer_recall_2: 0.1593 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8219 - val_softmax_layer_fscore_cls2: 0.2536
Epoch 15/50
60/60 [==============================] - 5s 86ms/step - loss: 0.2588 - softmax_layer_loss: 0.2588 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7083 - softmax_layer_recall_1: 0.5963 - softmax_layer_precision_2: 0.7414 - softmax_layer_recall_2: 0.4143 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6475 - softmax_layer_fscore_cls2: 0.5316 - val_loss: 0.2154 - val_softmax_layer_loss: 0.2154 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.8027 - val_softmax_layer_recall_1: 0.8741 - val_softmax_layer_precision_2: 0.6418 - val_softmax_layer_recall_2: 0.2119 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8368 - val_softmax_layer_fscore_cls2: 0.3186
Epoch 16/50
60/60 [==============================] - 5s 86ms/step - loss: 0.2541 - softmax_layer_loss: 0.2541 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.6973 - softmax_layer_recall_1: 0.5668 - softmax_layer_precision_2: 0.7673 - softmax_layer_recall_2: 0.4547 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.6253 - softmax_layer_fscore_cls2: 0.5710 - val_loss: 0.1619 - val_softmax_layer_loss: 0.1619 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7054 - val_softmax_layer_recall_1: 0.9605 - val_softmax_layer_precision_2: 0.6088 - val_softmax_layer_recall_2: 0.1355 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8134 - val_softmax_layer_fscore_cls2: 0.2216
Epoch 17/50
60/60 [==============================] - ETA: 0s - loss: 0.2661 - softmax_layer_loss: 0.2661 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.6644 - softmax_layer_recall_1: 0.5129 - softmax_layer_precision_2: 0.6780 - softmax_layer_recall_2: 0.3580 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.5789 - softmax_layer_fscore_cls2: 0.46862024-10-23 13:39:35.590456: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 5s 86ms/step - loss: 0.2661 - softmax_layer_loss: 0.2661 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.6644 - softmax_layer_recall_1: 0.5129 - softmax_layer_precision_2: 0.6780 - softmax_layer_recall_2: 0.3580 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.5789 - softmax_layer_fscore_cls2: 0.4686 - val_loss: 0.2859 - val_softmax_layer_loss: 0.2859 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5122 - val_softmax_layer_recall_1: 0.2209 - val_softmax_layer_precision_2: 0.6667 - val_softmax_layer_recall_2: 0.1937 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.3087 - val_softmax_layer_fscore_cls2: 0.3002
Epoch 18/50
60/60 [==============================] - 5s 88ms/step - loss: 0.2760 - softmax_layer_loss: 0.2760 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5489 - softmax_layer_recall_1: 0.3194 - softmax_layer_precision_2: 0.7398 - softmax_layer_recall_2: 0.3803 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4038 - softmax_layer_fscore_cls2: 0.5023 - val_loss: 0.2615 - val_softmax_layer_loss: 0.2615 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5306 - val_softmax_layer_recall_1: 0.1303 - val_softmax_layer_precision_2: 0.7460 - val_softmax_layer_recall_2: 0.3069 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2092 - val_softmax_layer_fscore_cls2: 0.4349
Epoch 19/50
60/60 [==============================] - 5s 88ms/step - loss: 0.2757 - softmax_layer_loss: 0.2757 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5817 - softmax_layer_recall_1: 0.3585 - softmax_layer_precision_2: 0.6822 - softmax_layer_recall_2: 0.3160 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4436 - softmax_layer_fscore_cls2: 0.4320 - val_loss: 0.2559 - val_softmax_layer_loss: 0.2559 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.6219 - val_softmax_layer_recall_1: 0.2701 - val_softmax_layer_precision_2: 0.6924 - val_softmax_layer_recall_2: 0.2606 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.3766 - val_softmax_layer_fscore_cls2: 0.3787
Epoch 20/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2841 - softmax_layer_loss: 0.2841 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5793 - softmax_layer_recall_1: 0.3540 - softmax_layer_precision_2: 0.6200 - softmax_layer_recall_2: 0.2887 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4395 - softmax_layer_fscore_cls2: 0.3940 - val_loss: 0.2269 - val_softmax_layer_loss: 0.2269 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.8632 - val_softmax_layer_recall_1: 0.8310 - val_softmax_layer_precision_2: 0.6324 - val_softmax_layer_recall_2: 0.2750 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8468 - val_softmax_layer_fscore_cls2: 0.3833
Epoch 21/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2801 - softmax_layer_loss: 0.2801 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5734 - softmax_layer_recall_1: 0.3367 - softmax_layer_precision_2: 0.6589 - softmax_layer_recall_2: 0.3018 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4243 - softmax_layer_fscore_cls2: 0.4139 - val_loss: 0.2186 - val_softmax_layer_loss: 0.2186 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7884 - val_softmax_layer_recall_1: 0.8765 - val_softmax_layer_precision_2: 0.3534 - val_softmax_layer_recall_2: 0.0860 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8302 - val_softmax_layer_fscore_cls2: 0.1384
Epoch 22/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2926 - softmax_layer_loss: 0.2926 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5855 - softmax_layer_recall_1: 0.3699 - softmax_layer_precision_2: 0.5690 - softmax_layer_recall_2: 0.2389 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4534 - softmax_layer_fscore_cls2: 0.3365 - val_loss: 0.2268 - val_softmax_layer_loss: 0.2268 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7219 - val_softmax_layer_recall_1: 0.6413 - val_softmax_layer_precision_2: 0.6260 - val_softmax_layer_recall_2: 0.2152 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.6792 - val_softmax_layer_fscore_cls2: 0.3202
Epoch 23/50
60/60 [==============================] - ETA: 0s - loss: 0.2890 - softmax_layer_loss: 0.2890 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5508 - softmax_layer_recall_1: 0.3057 - softmax_layer_precision_2: 0.6677 - softmax_layer_recall_2: 0.2784 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3932 - softmax_layer_fscore_cls2: 0.39292024-10-23 13:40:07.782374: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 5s 87ms/step - loss: 0.2890 - softmax_layer_loss: 0.2890 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5508 - softmax_layer_recall_1: 0.3057 - softmax_layer_precision_2: 0.6677 - softmax_layer_recall_2: 0.2784 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3932 - softmax_layer_fscore_cls2: 0.3929 - val_loss: 0.2780 - val_softmax_layer_loss: 0.2780 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5316 - val_softmax_layer_recall_1: 0.1710 - val_softmax_layer_precision_2: 0.5339 - val_softmax_layer_recall_2: 0.1614 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2588 - val_softmax_layer_fscore_cls2: 0.2479
Epoch 24/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2929 - softmax_layer_loss: 0.2929 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5497 - softmax_layer_recall_1: 0.3285 - softmax_layer_precision_2: 0.6109 - softmax_layer_recall_2: 0.2712 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4113 - softmax_layer_fscore_cls2: 0.3756 - val_loss: 0.2187 - val_softmax_layer_loss: 0.2187 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7779 - val_softmax_layer_recall_1: 0.9134 - val_softmax_layer_precision_2: 0.5720 - val_softmax_layer_recall_2: 0.2124 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.8402 - val_softmax_layer_fscore_cls2: 0.3098
Epoch 25/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2999 - softmax_layer_loss: 0.2999 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5591 - softmax_layer_recall_1: 0.3543 - softmax_layer_precision_2: 0.5730 - softmax_layer_recall_2: 0.2127 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4338 - softmax_layer_fscore_cls2: 0.3102 - val_loss: 0.2389 - val_softmax_layer_loss: 0.2389 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5877 - val_softmax_layer_recall_1: 0.2894 - val_softmax_layer_precision_2: 0.6122 - val_softmax_layer_recall_2: 0.2523 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.3878 - val_softmax_layer_fscore_cls2: 0.3573
Epoch 26/50
60/60 [==============================] - 5s 88ms/step - loss: 0.2859 - softmax_layer_loss: 0.2859 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.5757 - softmax_layer_recall_1: 0.3528 - softmax_layer_precision_2: 0.6536 - softmax_layer_recall_2: 0.2707 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.4375 - softmax_layer_fscore_cls2: 0.3829 - val_loss: 0.2170 - val_softmax_layer_loss: 0.2170 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5866 - val_softmax_layer_recall_1: 0.3795 - val_softmax_layer_precision_2: 0.4582 - val_softmax_layer_recall_2: 0.1844 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.4609 - val_softmax_layer_fscore_cls2: 0.2629
Epoch 27/50
60/60 [==============================] - 5s 87ms/step - loss: 0.2958 - softmax_layer_loss: 0.2958 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4903 - softmax_layer_recall_1: 0.2579 - softmax_layer_precision_2: 0.6085 - softmax_layer_recall_2: 0.2493 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3380 - softmax_layer_fscore_cls2: 0.3537 - val_loss: 0.2862 - val_softmax_layer_loss: 0.2862 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.5224 - val_softmax_layer_recall_1: 0.2120 - val_softmax_layer_precision_2: 0.4337 - val_softmax_layer_recall_2: 0.1118 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.3016 - val_softmax_layer_fscore_cls2: 0.1778
Epoch 28/50
60/60 [==============================] - 5s 90ms/step - loss: 0.2976 - softmax_layer_loss: 0.2976 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4448 - softmax_layer_recall_1: 0.2281 - softmax_layer_precision_2: 0.5482 - softmax_layer_recall_2: 0.2311 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3015 - softmax_layer_fscore_cls2: 0.3251 - val_loss: 0.2911 - val_softmax_layer_loss: 0.2911 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.3663 - val_softmax_layer_recall_1: 0.1017 - val_softmax_layer_precision_2: 0.2900 - val_softmax_layer_recall_2: 0.0909 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1592 - val_softmax_layer_fscore_cls2: 0.1384
Epoch 29/50
60/60 [==============================] - ETA: 0s - loss: 0.2957 - softmax_layer_loss: 0.2957 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4558 - softmax_layer_recall_1: 0.2271 - softmax_layer_precision_2: 0.5233 - softmax_layer_recall_2: 0.2080 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3032 - softmax_layer_fscore_cls2: 0.29762024-10-23 13:40:40.477920: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 6s 93ms/step - loss: 0.2957 - softmax_layer_loss: 0.2957 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4558 - softmax_layer_recall_1: 0.2271 - softmax_layer_precision_2: 0.5233 - softmax_layer_recall_2: 0.2080 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3032 - softmax_layer_fscore_cls2: 0.2976 - val_loss: 0.2400 - val_softmax_layer_loss: 0.2400 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7594 - val_softmax_layer_recall_1: 0.8447 - val_softmax_layer_precision_2: 0.3992 - val_softmax_layer_recall_2: 0.1115 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.7998 - val_softmax_layer_fscore_cls2: 0.1743
Epoch 30/50
60/60 [==============================] - 6s 95ms/step - loss: 0.3012 - softmax_layer_loss: 0.3012 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4271 - softmax_layer_recall_1: 0.2174 - softmax_layer_precision_2: 0.5829 - softmax_layer_recall_2: 0.2346 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2882 - softmax_layer_fscore_cls2: 0.3345 - val_loss: 0.2350 - val_softmax_layer_loss: 0.2350 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.4226 - val_softmax_layer_recall_1: 0.2146 - val_softmax_layer_precision_2: 0.1914 - val_softmax_layer_recall_2: 0.0581 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2847 - val_softmax_layer_fscore_cls2: 0.0891
Epoch 31/50
60/60 [==============================] - 6s 98ms/step - loss: 0.3044 - softmax_layer_loss: 0.3044 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4256 - softmax_layer_recall_1: 0.2308 - softmax_layer_precision_2: 0.5181 - softmax_layer_recall_2: 0.2040 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2993 - softmax_layer_fscore_cls2: 0.2927 - val_loss: 0.2872 - val_softmax_layer_loss: 0.2872 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.2671 - val_softmax_layer_recall_1: 0.0851 - val_softmax_layer_precision_2: 0.3141 - val_softmax_layer_recall_2: 0.0947 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1291 - val_softmax_layer_fscore_cls2: 0.1455
Epoch 32/50
60/60 [==============================] - 6s 101ms/step - loss: 0.3006 - softmax_layer_loss: 0.3006 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4485 - softmax_layer_recall_1: 0.2274 - softmax_layer_precision_2: 0.5768 - softmax_layer_recall_2: 0.2159 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.3017 - softmax_layer_fscore_cls2: 0.3142 - val_loss: 0.2364 - val_softmax_layer_loss: 0.2364 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.6254 - val_softmax_layer_recall_1: 0.4689 - val_softmax_layer_precision_2: 0.3638 - val_softmax_layer_recall_2: 0.1241 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.5359 - val_softmax_layer_fscore_cls2: 0.1851
Epoch 33/50
60/60 [==============================] - 6s 104ms/step - loss: 0.3027 - softmax_layer_loss: 0.3027 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4144 - softmax_layer_recall_1: 0.2066 - softmax_layer_precision_2: 0.5446 - softmax_layer_recall_2: 0.1973 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2757 - softmax_layer_fscore_cls2: 0.2897 - val_loss: 0.2407 - val_softmax_layer_loss: 0.2407 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.4554 - val_softmax_layer_recall_1: 0.2247 - val_softmax_layer_precision_2: 0.4124 - val_softmax_layer_recall_2: 0.2089 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.3009 - val_softmax_layer_fscore_cls2: 0.2773
Epoch 34/50
60/60 [==============================] - ETA: 0s - loss: 0.3033 - softmax_layer_loss: 0.3033 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4014 - softmax_layer_recall_1: 0.2002 - softmax_layer_precision_2: 0.5050 - softmax_layer_recall_2: 0.1824 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2672 - softmax_layer_fscore_cls2: 0.26802024-10-23 13:41:11.324559: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 6s 107ms/step - loss: 0.3033 - softmax_layer_loss: 0.3033 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.4014 - softmax_layer_recall_1: 0.2002 - softmax_layer_precision_2: 0.5050 - softmax_layer_recall_2: 0.1824 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2672 - softmax_layer_fscore_cls2: 0.2680 - val_loss: 0.2878 - val_softmax_layer_loss: 0.2878 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1660 - val_softmax_layer_recall_1: 0.0350 - val_softmax_layer_precision_2: 0.5192 - val_softmax_layer_recall_2: 0.1750 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0577 - val_softmax_layer_fscore_cls2: 0.2618
Epoch 35/50
60/60 [==============================] - 7s 111ms/step - loss: 0.3047 - softmax_layer_loss: 0.3047 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3484 - softmax_layer_recall_1: 0.1549 - softmax_layer_precision_2: 0.5546 - softmax_layer_recall_2: 0.2094 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2145 - softmax_layer_fscore_cls2: 0.3040 - val_loss: 0.2530 - val_softmax_layer_loss: 0.2530 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.3330 - val_softmax_layer_recall_1: 0.1169 - val_softmax_layer_precision_2: 0.4749 - val_softmax_layer_recall_2: 0.2201 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1731 - val_softmax_layer_fscore_cls2: 0.3008
Epoch 36/50
60/60 [==============================] - 7s 115ms/step - loss: 0.3066 - softmax_layer_loss: 0.3066 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3628 - softmax_layer_recall_1: 0.1793 - softmax_layer_precision_2: 0.5062 - softmax_layer_recall_2: 0.1965 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2400 - softmax_layer_fscore_cls2: 0.2831 - val_loss: 0.2740 - val_softmax_layer_loss: 0.2740 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.4612 - val_softmax_layer_recall_1: 0.1813 - val_softmax_layer_precision_2: 0.2498 - val_softmax_layer_recall_2: 0.0865 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.2603 - val_softmax_layer_fscore_cls2: 0.1285
Epoch 37/50
60/60 [==============================] - 7s 119ms/step - loss: 0.3110 - softmax_layer_loss: 0.3110 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3234 - softmax_layer_recall_1: 0.1332 - softmax_layer_precision_2: 0.5063 - softmax_layer_recall_2: 0.1844 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1887 - softmax_layer_fscore_cls2: 0.2703 - val_loss: 0.3081 - val_softmax_layer_loss: 0.3081 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1669 - val_softmax_layer_recall_1: 0.0413 - val_softmax_layer_precision_2: 0.2945 - val_softmax_layer_recall_2: 0.0887 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0662 - val_softmax_layer_fscore_cls2: 0.1364
Epoch 38/50
60/60 [==============================] - 8s 125ms/step - loss: 0.3092 - softmax_layer_loss: 0.3092 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3322 - softmax_layer_recall_1: 0.1476 - softmax_layer_precision_2: 0.4705 - softmax_layer_recall_2: 0.1746 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2044 - softmax_layer_fscore_cls2: 0.2546 - val_loss: 0.2945 - val_softmax_layer_loss: 0.2945 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.3402 - val_softmax_layer_recall_1: 0.1044 - val_softmax_layer_precision_2: 0.3253 - val_softmax_layer_recall_2: 0.0951 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1597 - val_softmax_layer_fscore_cls2: 0.1472
Epoch 39/50
60/60 [==============================] - ETA: 0s - loss: 0.3161 - softmax_layer_loss: 0.3161 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3395 - softmax_layer_recall_1: 0.1585 - softmax_layer_precision_2: 0.4776 - softmax_layer_recall_2: 0.1762 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2161 - softmax_layer_fscore_cls2: 0.25742024-10-23 13:41:47.675325: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 8s 127ms/step - loss: 0.3161 - softmax_layer_loss: 0.3161 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3395 - softmax_layer_recall_1: 0.1585 - softmax_layer_precision_2: 0.4776 - softmax_layer_recall_2: 0.1762 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.2161 - softmax_layer_fscore_cls2: 0.2574 - val_loss: 0.3108 - val_softmax_layer_loss: 0.3108 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.3173 - val_softmax_layer_recall_1: 0.1007 - val_softmax_layer_precision_2: 0.3017 - val_softmax_layer_recall_2: 0.0824 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1529 - val_softmax_layer_fscore_cls2: 0.1295
Epoch 40/50
60/60 [==============================] - 8s 132ms/step - loss: 0.3126 - softmax_layer_loss: 0.3126 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2985 - softmax_layer_recall_1: 0.1272 - softmax_layer_precision_2: 0.4843 - softmax_layer_recall_2: 0.1753 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1783 - softmax_layer_fscore_cls2: 0.2574 - val_loss: 0.3254 - val_softmax_layer_loss: 0.3254 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1660 - val_softmax_layer_recall_1: 0.0457 - val_softmax_layer_precision_2: 0.2595 - val_softmax_layer_recall_2: 0.0752 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0717 - val_softmax_layer_fscore_cls2: 0.1167
Epoch 41/50
60/60 [==============================] - 8s 128ms/step - loss: 0.3187 - softmax_layer_loss: 0.3187 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2254 - softmax_layer_recall_1: 0.0899 - softmax_layer_precision_2: 0.5071 - softmax_layer_recall_2: 0.1736 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1285 - softmax_layer_fscore_cls2: 0.2586 - val_loss: 0.2854 - val_softmax_layer_loss: 0.2854 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1362 - val_softmax_layer_recall_1: 0.0392 - val_softmax_layer_precision_2: 0.2804 - val_softmax_layer_recall_2: 0.1053 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0609 - val_softmax_layer_fscore_cls2: 0.1531
Epoch 42/50
60/60 [==============================] - 8s 127ms/step - loss: 0.3200 - softmax_layer_loss: 0.3200 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2853 - softmax_layer_recall_1: 0.1145 - softmax_layer_precision_2: 0.4450 - softmax_layer_recall_2: 0.1592 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1634 - softmax_layer_fscore_cls2: 0.2345 - val_loss: 0.2564 - val_softmax_layer_loss: 0.2564 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.7056 - val_softmax_layer_recall_1: 0.6419 - val_softmax_layer_precision_2: 0.3694 - val_softmax_layer_recall_2: 0.1030 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.6723 - val_softmax_layer_fscore_cls2: 0.1611
Epoch 43/50
60/60 [==============================] - ETA: 0s - loss: 0.3193 - softmax_layer_loss: 0.3193 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3398 - softmax_layer_recall_1: 0.1386 - softmax_layer_precision_2: 0.4478 - softmax_layer_recall_2: 0.1598 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1969 - softmax_layer_fscore_cls2: 0.23552024-10-23 13:42:19.615494: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 8s 135ms/step - loss: 0.3193 - softmax_layer_loss: 0.3193 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.3398 - softmax_layer_recall_1: 0.1386 - softmax_layer_precision_2: 0.4478 - softmax_layer_recall_2: 0.1598 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1969 - softmax_layer_fscore_cls2: 0.2355 - val_loss: 0.3195 - val_softmax_layer_loss: 0.3195 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1670 - val_softmax_layer_recall_1: 0.0408 - val_softmax_layer_precision_2: 0.3113 - val_softmax_layer_recall_2: 0.0839 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0656 - val_softmax_layer_fscore_cls2: 0.1321
Epoch 44/50
60/60 [==============================] - 8s 132ms/step - loss: 0.3127 - softmax_layer_loss: 0.3127 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2676 - softmax_layer_recall_1: 0.1091 - softmax_layer_precision_2: 0.4491 - softmax_layer_recall_2: 0.1590 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1550 - softmax_layer_fscore_cls2: 0.2348 - val_loss: 0.2566 - val_softmax_layer_loss: 0.2566 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1083 - val_softmax_layer_recall_1: 0.0394 - val_softmax_layer_precision_2: 0.1738 - val_softmax_layer_recall_2: 0.0620 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0578 - val_softmax_layer_fscore_cls2: 0.0914
Epoch 45/50
60/60 [==============================] - 8s 131ms/step - loss: 0.3200 - softmax_layer_loss: 0.3200 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2060 - softmax_layer_recall_1: 0.0807 - softmax_layer_precision_2: 0.4095 - softmax_layer_recall_2: 0.1394 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1160 - softmax_layer_fscore_cls2: 0.2080 - val_loss: 0.2722 - val_softmax_layer_loss: 0.2722 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1778 - val_softmax_layer_recall_1: 0.0491 - val_softmax_layer_precision_2: 0.2610 - val_softmax_layer_recall_2: 0.0841 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0770 - val_softmax_layer_fscore_cls2: 0.1272
Epoch 46/50
60/60 [==============================] - 8s 127ms/step - loss: 0.3157 - softmax_layer_loss: 0.3157 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2683 - softmax_layer_recall_1: 0.1011 - softmax_layer_precision_2: 0.4580 - softmax_layer_recall_2: 0.1584 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1469 - softmax_layer_fscore_cls2: 0.2354 - val_loss: 0.3069 - val_softmax_layer_loss: 0.3069 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1941 - val_softmax_layer_recall_1: 0.0447 - val_softmax_layer_precision_2: 0.2489 - val_softmax_layer_recall_2: 0.0831 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0727 - val_softmax_layer_fscore_cls2: 0.1246
Epoch 47/50
60/60 [==============================] - ETA: 0s - loss: 0.3208 - softmax_layer_loss: 0.3208 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2154 - softmax_layer_recall_1: 0.0895 - softmax_layer_precision_2: 0.3974 - softmax_layer_recall_2: 0.1507 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1264 - softmax_layer_fscore_cls2: 0.21852024-10-23 13:42:51.065355: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
60/60 [==============================] - 8s 124ms/step - loss: 0.3208 - softmax_layer_loss: 0.3208 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2154 - softmax_layer_recall_1: 0.0895 - softmax_layer_precision_2: 0.3974 - softmax_layer_recall_2: 0.1507 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1264 - softmax_layer_fscore_cls2: 0.2185 - val_loss: 0.3307 - val_softmax_layer_loss: 0.3307 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.2647 - val_softmax_layer_recall_1: 0.0655 - val_softmax_layer_precision_2: 0.2292 - val_softmax_layer_recall_2: 0.0615 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.1050 - val_softmax_layer_fscore_cls2: 0.0969
Epoch 48/50
60/60 [==============================] - 7s 120ms/step - loss: 0.3258 - softmax_layer_loss: 0.3258 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2156 - softmax_layer_recall_1: 0.0800 - softmax_layer_precision_2: 0.3724 - softmax_layer_recall_2: 0.1270 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1167 - softmax_layer_fscore_cls2: 0.1894 - val_loss: 0.2906 - val_softmax_layer_loss: 0.2906 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1731 - val_softmax_layer_recall_1: 0.0464 - val_softmax_layer_precision_2: 0.2418 - val_softmax_layer_recall_2: 0.0769 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0731 - val_softmax_layer_fscore_cls2: 0.1167
Epoch 49/50
60/60 [==============================] - 7s 120ms/step - loss: 0.3194 - softmax_layer_loss: 0.3194 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2680 - softmax_layer_recall_1: 0.1102 - softmax_layer_precision_2: 0.3576 - softmax_layer_recall_2: 0.1459 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1562 - softmax_layer_fscore_cls2: 0.2072 - val_loss: 0.2663 - val_softmax_layer_loss: 0.2663 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1581 - val_softmax_layer_recall_1: 0.0409 - val_softmax_layer_precision_2: 0.3706 - val_softmax_layer_recall_2: 0.1323 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0650 - val_softmax_layer_fscore_cls2: 0.1950
Epoch 50/50
60/60 [==============================] - 7s 120ms/step - loss: 0.3213 - softmax_layer_loss: 0.3213 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.2412 - softmax_layer_recall_1: 0.0847 - softmax_layer_precision_2: 0.4650 - softmax_layer_recall_2: 0.1597 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.1253 - softmax_layer_fscore_cls2: 0.2377 - val_loss: 0.2811 - val_softmax_layer_loss: 0.2811 - val_softmax_layer_precision: 0.0000e+00 - val_softmax_layer_recall: 0.0000e+00 - val_softmax_layer_precision_1: 0.1625 - val_softmax_layer_recall_1: 0.0253 - val_softmax_layer_precision_2: 0.1541 - val_softmax_layer_recall_2: 0.0992 - val_softmax_layer_fscore_cls0: 0.0000e+00 - val_softmax_layer_fscore_cls1: 0.0438 - val_softmax_layer_fscore_cls2: 0.1207
2024-10-23 13:43:13.620742: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /data/output/savedmodel_v11: FAILED_PRECONDITION: /data/output/savedmodel_v11; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
7/7 [==============================] - 0s 38ms/step - loss: 0.1979 - softmax_layer_loss: 0.1979 - softmax_layer_precision: 0.0000e+00 - softmax_layer_recall: 0.0000e+00 - softmax_layer_precision_1: 0.7223 - softmax_layer_recall_1: 0.9387 - softmax_layer_precision_2: 0.7777 - softmax_layer_recall_2: 0.4261 - softmax_layer_fscore_cls0: 0.0000e+00 - softmax_layer_fscore_cls1: 0.8164 - softmax_layer_fscore_cls2: 0.5506
loss: 19.79
softmax_layer_loss: 19.79
softmax_layer_precision: 0.00
softmax_layer_recall: 0.00
softmax_layer_precision_1: 72.23
softmax_layer_recall_1: 93.87
softmax_layer_precision_2: 77.77
softmax_layer_recall_2: 42.61
softmax_layer_fscore_cls0: 0.00
softmax_layer_fscore_cls1: 81.64
softmax_layer_fscore_cls2: 55.06
otbuser@ebef67e1b7c4:/data$ python inference_v11.py \
  --model_dir /data/output/savedmodel_v11
2024-10-23 13:43:50 (INFO) [pyotb] Successfully loaded 117 OTB applications
2024-10-23 13:43:50 (INFO) [pyotb] TensorflowModelServe: argument for parameter "source1.il" was converted to list
2024-10-23 13:43:50 (INFO) [pyotb] TensorflowModelServe: argument for parameter "output.names" was converted to list
2024-10-23 13:43:50.418053: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /data/output/savedmodel_v11
2024-10-23 13:43:50.428991: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }
2024-10-23 13:43:50.429164: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /data/output/savedmodel_v11
2024-10-23 13:43:50.431281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-23 13:43:50.483243: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled
2024-10-23 13:43:50.499305: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.
2024-10-23 13:43:50.508526: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:118] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency
2024-10-23 13:43:50.727258: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2024-10-23 13:43:50.727301: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2024-10-23 13:43:50.757087: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.
2024-10-23 13:43:50.757961: W tensorflow/core/profiler/convert/xplane_to_step_stats.cc:78] GPU trace was not collected.
2024-10-23 13:43:50.758565: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2024-10-23 13:43:50.759337: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /data/output/savedmodel_v11
2024-10-23 13:43:50.788437: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2024-10-23 13:43:50.788470: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2024-10-23 13:43:50.788593: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.
2024-10-23 13:43:50.788623: W tensorflow/core/profiler/convert/xplane_to_step_stats.cc:78] GPU trace was not collected.
2024-10-23 13:43:50.788638: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2024-10-23 13:43:50.788898: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 371197 microseconds.
2024-10-23 13:43:50 (INFO): Loading metadata from official product
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Source info :
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Receptive field  : [128, 128]
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Placeholder name : input_ge
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Output spacing ratio: 1
2024-10-23 13:43:50 (INFO) TensorflowModelServe: The TensorFlow model is used in fully convolutional mode
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Setting background value to 0
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Output field of expression: [64, 64]
2024-10-23 13:43:50 (WARNING) TensorflowModelServe: Aligning the tiling to the output expression field for better performances (dim 0). New value set to 64
2024-10-23 13:43:50 (WARNING) TensorflowModelServe: Aligning the tiling to the output expression field for better performances (dim 1). New value set to 64
2024-10-23 13:43:50 (INFO) TensorflowModelServe: Force tiling with squared tiles of [64, 64]
2024-10-23 13:43:50 (INFO): Default RAM limit for OTB is 256 MB
2024-10-23 13:43:50 (INFO): GDAL maximum cache size is 392 MB
2024-10-23 13:43:50 (INFO): OTB will use at most 8 threads
2024-10-23 13:43:50 (INFO): Estimated memory for full processing: 445.386MB (avail.: 256 MB), optimal image partitioning: 2 blocks
2024-10-23 13:43:50 (INFO): File /data/map_v11.tif will be written in 4 blocks of 1184x1184 pixels
Writing /data/map_v11.tif...: 0% [                                              Writing /data/map_v11.tif...: 2% [*                                             Writing /data/map_v11.tif...: 4% [**                                            Writing /data/map_v11.tif...: 6% [***                                           Writing /data/map_v11.tif...: 8% [****                                          Writing /data/map_v11.tif...: 10% [*****                                        Writing /data/map_v11.tif...: 12% [******                                       Writing /data/map_v11.tif...: 14% [*******                                      Writing /data/map_v11.tif...: 16% [********                                     Writing /data/map_v11.tif...: 18% [*********                                    Writing /data/map_v11.tif...: 20% [**********                                   Writing /data/map_v11.tif...: 22% [***********                                  Writing /data/map_v11.tif...: 24% [************                                 Writing /data/map_v11.tif...: 26% [*************                                Writing /data/map_v11.tif...: 28% [**************                               Writing /data/map_v11.tif...: 30% [***************                              Writing /data/map_v11.tif...: 32% [****************                             Writing /data/map_v11.tif...: 34% [*****************                            Writing /data/map_v11.tif...: 36% [******************                           Writing /data/map_v11.tif...: 38% [*******************                          Writing /data/map_v11.tif...: 40% [********************                         Writing /data/map_v11.tif...: 42% [*********************                        Writing /data/map_v11.tif...: 44% [**********************                       Writing /data/map_v11.tif...: 46% [***********************                      Writing /data/map_v11.tif...: 48% [************************                     Writing /data/map_v11.tif...: 50% [*************************                    Writing /data/map_v11.tif...: 52% [**************************                   Writing /data/map_v11.tif...: 54% [***************************                  Writing /data/map_v11.tif...: 56% [****************************                 Writing /data/map_v11.tif...: 58% [*****************************                Writing /data/map_v11.tif...: 60% [******************************               Writing /data/map_v11.tif...: 62% [*******************************              Writing /data/map_v11.tif...: 64% [********************************             Writing /data/map_v11.tif...: 66% [*********************************            Writing /data/map_v11.tif...: 68% [**********************************           Writing /data/map_v11.tif...: 70% [***********************************          Writing /data/map_v11.tif...: 72% [************************************         Writing /data/map_v11.tif...: 74% [*************************************        Writing /data/map_v11.tif...: 76% [**************************************       Writing /data/map_v11.tif...: 78% [***************************************      Writing /data/map_v11.tif...: 80% [****************************************     Writing /data/map_v11.tif...: 82% [*****************************************    Writing /data/map_v11.tif...: 84% [******************************************   Writing /data/map_v11.tif...: 86% [*******************************************  Writing /data/map_v11.tif...: 88% [******************************************** Writing /data/map_v11.tif...: 90% [*********************************************Writing /data/map_v11.tif...: 92% [*********************************************Writing /data/map_v11.tif...: 94% [*********************************************Writing /data/map_v11.tif...: 96% [*********************************************Writing /data/map_v11.tif...: 98% [*********************************************Writing /data/map_v11.tif...: 100% [**************************************************] (11s)